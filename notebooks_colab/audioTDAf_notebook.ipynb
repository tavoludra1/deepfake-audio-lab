{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tavoludra1/deepfake-audio-lab/blob/master/notebooks_colab/audioTDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-y8td4NZ5uia",
        "outputId": "19f6acde-4087-4ce7-cc45-ef28a9478f35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš™ï¸ Provisioning Research Environment... (This may take 1-2 minutes)\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "umap-learn 0.5.11 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "imbalanced-learn 0.14.1 requires scikit-learn<2,>=1.4.2, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "esda 2.8.1 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "spopt 0.7.0 requires scikit-learn>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "libpysal 4.14.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "mapclassify 2.10.0 requires scikit-learn>=1.4, but you have scikit-learn 1.3.2 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "giotto-tda 0.6.2 requires scikit-learn==1.3.2, but you have scikit-learn 1.8.0 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… Dependencies Installed. System ready for Mathematical Audit.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# LABORATORY PROVISIONING: Scientific Dependencies\n",
        "# Installs High-Performance Topology (Giotto-TDA) & Audio (Librosa) libs\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"âš™ï¸ Provisioning Research Environment... (This may take 1-2 minutes)\")\n",
        "\n",
        "# Install Giotto-TDA for Topological Data Analysis (The core of your thesis)\n",
        "!pip install -q giotto-tda\n",
        "\n",
        "# Install Librosa for audio signal processing (Standard in MPI-IS)\n",
        "!pip install -q librosa\n",
        "\n",
        "# Install UMAP for manifold visualization (Useful for thesis plots later)\n",
        "!pip install -q umap-learn\n",
        "\n",
        "print(\"âœ… Dependencies Installed. System ready for Mathematical Audit.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YCLu1x4S7JUD",
        "outputId": "f70ec8fd-8f8b-4b65-b869-433b07ae6377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”§ Aligning Research Dependencies...\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "giotto-tda 0.6.2 requires scikit-learn==1.3.2, but you have scikit-learn 1.5.2 which is incompatible.\n",
            "umap-learn 0.5.11 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… Dependency Fixed.\n",
            "âš ï¸ CRITICAL: You must RESTART THE RUNTIME now for changes to take effect.\n",
            "   (Go to 'Runtime' > 'Restart Session' or 'Restart Runtime')\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# ENVIRONMENT RECOVERY: Dependency Alignment\n",
        "# Standard: Fix version conflict between Scikit-Learn 1.6+ and Giotto-TDA\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"ðŸ”§ Aligning Research Dependencies...\")\n",
        "\n",
        "# Force install a version of scikit-learn that supports 'force_all_finite'\n",
        "!pip install -q \"scikit-learn<1.6.0\"\n",
        "\n",
        "print(\"âœ… Dependency Fixed.\")\n",
        "print(\"âš ï¸ CRITICAL: You must RESTART THE RUNTIME now for changes to take effect.\")\n",
        "print(\"   (Go to 'Runtime' > 'Restart Session' or 'Restart Runtime')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4YFt2Gb2LIc"
      },
      "source": [
        "# ConfiguraciÃ³n del Entorno y Estructura de Directorios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkZqmJZ_1xcH",
        "outputId": "33cd2845-c5c6-41f0-cbbf-a8284710746a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Mission-critical structure initialized at /content/deepfake-audio-lab\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# LABORATORY SETUP: Deepfake Audio Topological Analysis\n",
        "# Standard: Max Planck Institute / Google DeepMind\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Project root definition\n",
        "PROJECT_NAME = \"deepfake-audio-lab\"\n",
        "ROOT_DIR = Path(f\"/content/{PROJECT_NAME}\")\n",
        "\n",
        "# High-level architecture folders\n",
        "folders = [\n",
        "    \"src/deepfake_audio/domain\",\n",
        "    \"src/deepfake_audio/infrastructure/features\",\n",
        "    \"src/deepfake_audio/infrastructure/numerics\",\n",
        "    \"src/deepfake_audio/infrastructure/cuda\",\n",
        "    \"src/deepfake_audio/application\",\n",
        "    \"configs/sweeps\",\n",
        "    \"docs\",\n",
        "    \"tests\",\n",
        "    \"runs\"\n",
        "]\n",
        "\n",
        "for folder in folders:\n",
        "    (ROOT_DIR / folder).mkdir(parents=True, exist_ok=True)\n",
        "    (ROOT_DIR / folder / \"__init__.py\").touch()\n",
        "\n",
        "print(f\"âœ… Mission-critical structure initialized at {ROOT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkiOUvxi2Tnp"
      },
      "source": [
        "# ImplementaciÃ³n de la Capa de Fiabilidad (Numerics & Shapes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra3l1bV66iSK",
        "outputId": "c8d9a518-2c1a-46ae-930d-1870f9f7a280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/deepfake-audio-lab/src/deepfake_audio/infrastructure/numerics/stability.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/deepfake-audio-lab/src/deepfake_audio/infrastructure/numerics/stability.py\n",
        "\"\"\"\n",
        "Numerical Stability Layer - Standard ISO/IEEE for Mission Critical AI.\n",
        "Prevents division by zero, NaNs, and Infs during high-dimensional audio processing.\n",
        "\"\"\"\n",
        "import torch\n",
        "import logging\n",
        "\n",
        "class NumericalGuard:\n",
        "    @staticmethod\n",
        "    def safe_divide(numerator: torch.Tensor, denominator: torch.Tensor, eps: float = 1e-10) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Performs division with epsilon padding to prevent NaN results.\n",
        "        Formula: x / (y + eps)\n",
        "        \"\"\"\n",
        "        return numerator / (denominator + eps)\n",
        "\n",
        "    @staticmethod\n",
        "    def safe_log(x: torch.Tensor, eps: float = 1e-10) -> torch.Tensor:\n",
        "        \"\"\"Computes stable log to prevent -inf in spectral domains.\"\"\"\n",
        "        return torch.log(x + eps)\n",
        "\n",
        "    @staticmethod\n",
        "    def validate_tensor(tensor: torch.Tensor, name: str):\n",
        "        \"\"\"Standard DARPA check for tensor integrity.\"\"\"\n",
        "        if not torch.isfinite(tensor).all():\n",
        "            logging.error(f\"CRITICAL: Numerical instability in {name}\")\n",
        "            raise ArithmeticError(f\"System Lock Prevention: Non-finite values in {name}\")\n",
        "        return True\n",
        "\n",
        "    @staticmethod\n",
        "    def shape_assertion(tensor: torch.Tensor, expected_shape: tuple, context: str):\n",
        "        \"\"\"Strict shape checking to prevent broadcasting errors.\"\"\"\n",
        "        if tensor.shape != expected_shape:\n",
        "            raise TypeError(f\"Data Structure Mismatch in {context}: Got {tensor.shape}, expected {expected_shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P-8QOjg22eB"
      },
      "source": [
        "# ExtracciÃ³n TopolÃ³gica (Hypothesis Validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhJH81CC23E-",
        "outputId": "f179edd4-b1d3-43ba-c781-351cca1f4ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/deepfake-audio-lab/src/deepfake_audio/infrastructure/features/topological_engine.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {ROOT_DIR}/src/deepfake_audio/infrastructure/features/topological_engine.py\n",
        "\"\"\"\n",
        "Topological Signature Engine for Deepfake Detection.\n",
        "Implements Takens Embedding and Persistent Homology.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "from gtda.homology import VietorisRipsPersistence\n",
        "from gtda.time_series import TakensEmbedding\n",
        "\n",
        "class SonicSignature:\n",
        "    def __init__(self, dimension: int = 3, delay: int = 1):\n",
        "        # Time delay embedding parameters\n",
        "        self.embedder = TakensEmbedding(dimension=dimension, time_delay=delay)\n",
        "        # Homology: 0 (connected components), 1 (loops/holes)\n",
        "        self.homology = VietorisRipsPersistence(homology_dimensions=[0, 1])\n",
        "\n",
        "    def generate_fingerprint(self, signal: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Extracts the topological manifold of the audio signal.\n",
        "        The hypothesis is that Deepfakes exhibit 'broken' topological manifolds.\n",
        "        \"\"\"\n",
        "        # CRITICAL FIX: GTDA expects shape (n_samples, n_time_steps)\n",
        "        # If signal is (N,), we reshape to (1, N) representing one time series.\n",
        "        if signal.ndim == 1:\n",
        "            signal = signal.reshape(1, -1)\n",
        "\n",
        "        # Phase space reconstruction\n",
        "        # Output shape: (n_samples, n_points, dimension)\n",
        "        embedded = self.embedder.fit_transform(signal)\n",
        "\n",
        "        # Compute persistent diagrams (H0, H1)\n",
        "        # Output shape: (n_samples, n_features, 3)\n",
        "        diagrams = self.homology.fit_transform(embedded)\n",
        "        return diagrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T39or0uH3AUf"
      },
      "source": [
        "# MÃ³dulo de AceleraciÃ³n CUDA (C++ Interface)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzMKnGJQ3BXs",
        "outputId": "39f644ab-8226-4776-85e9-7671519533e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/deepfake-audio-lab/src/deepfake_audio/infrastructure/cuda/ops.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile {ROOT_DIR}/src/deepfake_audio/infrastructure/cuda/ops.cu\n",
        "/*\n",
        "* CUDA Kernel for accelerated feature normalization.\n",
        "* Designed for high-throughput audio preprocessing in Colab Pro.\n",
        "*/\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void normalize_audio_kernel(float* data, float eps, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        // Implementation of safety padding at GPU level\n",
        "        data[idx] = data[idx] / (abs(data[idx]) + eps);\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GedRV-go3Fgh"
      },
      "source": [
        "# DocumentaciÃ³n de Protocolo (Thesis Logic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpcUAaTi3GHR",
        "outputId": "c03ff76f-bb9b-4d47-f037-e56fe19cb599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/deepfake-audio-lab/docs/METHODOLOGY.md\n"
          ]
        }
      ],
      "source": [
        "%%writefile {ROOT_DIR}/docs/METHODOLOGY.md\n",
        "# Mathematical Methodology & Corpus Validation\n",
        "\n",
        "## 1. Hypothesis: Topological Invariants in Synthetic Speech\n",
        "The core hypothesis posits that synthetic speech generation (GANs/Diffusers) fails to reconstruct the underlying **attractor manifold** of human vocal folds.\n",
        "\n",
        "## 2. Mathematical Formalism\n",
        "- **Embedding:** We use the *Takensâ€™ Embedding Theorem* to reconstruct the phase space:\n",
        "  $x(t) \\to [x(t), x(t+\\tau), ..., x(t+(d-1)\\tau)]$\n",
        "- **Persistence:** We compute the persistence landscape $\\Lambda(k, t)$ to detect structural anomalies.\n",
        "\n",
        "## 3. Numerical Rigor\n",
        "Implementation follows the **NASA Software Engineering Laboratory (SEL)** standards for error handling and data structure validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWc8DuyO3VwH"
      },
      "source": [
        "# Trainer Engine con PrecisiÃ³n Mixta y Guardias NumÃ©ricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH6bnQ0z3W8R",
        "outputId": "27eaf7a1-a1a0-47bb-f8f5-36bbd63d13de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/deepfake-audio-lab/src/deepfake_audio/application/trainer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {ROOT_DIR}/src/deepfake_audio/application/trainer.py\n",
        "\"\"\"\n",
        "Mission-Critical Trainer Engine.\n",
        "Implements Automatic Mixed Precision (AMP) and Gradient Clipping.\n",
        "Standard: Google DeepMind Research Engineering.\n",
        "\"\"\"\n",
        "import torch\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm.auto import tqdm\n",
        "import logging\n",
        "from ..infrastructure.numerics.stability import NumericalGuard\n",
        "\n",
        "class ResearchTrainer:\n",
        "    def __init__(self, model, optimizer, criterion, device, config):\n",
        "        self.model = model.to(device)\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "        self.config = config\n",
        "        self.scaler = GradScaler() # Optimization for Colab Pro GPUs\n",
        "        self.guard = NumericalGuard()\n",
        "\n",
        "    def train_epoch(self, dataloader):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
        "            data, target = data.to(self.device), target.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # Mission Critical: Autocast for memory efficiency and speed\n",
        "            with autocast():\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "\n",
        "                # Check for NaNs before backward pass\n",
        "                self.guard.validate_tensor(loss, f\"Loss_Batch_{batch_idx}\")\n",
        "\n",
        "            # Scales loss and calls backward() to create scaled gradients\n",
        "            self.scaler.scale(loss).backward()\n",
        "\n",
        "            # Gradient Clipping: Prevents exploding gradients (Standard in DeepMind)\n",
        "            self.scaler.unscale_(self.optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "\n",
        "            self.scaler.step(self.optimizer)\n",
        "            self.scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def validate(self, dataloader):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in dataloader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        return correct / len(dataloader.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5rqHl6l3bRx"
      },
      "source": [
        "# ImplementaciÃ³n de la Capa de Identidad SÃ³nica (Deep Learning Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q74uxoWK3cGr",
        "outputId": "05748a8e-8a40-4f7b-9a8a-b658bcd14daf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/deepfake-audio-lab/src/deepfake_audio/domain/models.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {ROOT_DIR}/src/deepfake_audio/domain/models.py\n",
        "\"\"\"\n",
        "Deep Learning Architectures for Sonic Signature Verification.\n",
        "Standard: Microsoft Research / NeurIPS high-level implementation.\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SonicIdentityNet(nn.Module):\n",
        "    def __init__(self, input_channels=1, num_classes=2):\n",
        "        super(SonicIdentityNet, self).__init__()\n",
        "        # Convolutional Backbone for Spectral Features\n",
        "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Global Average Pooling to handle variable audio lengths\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Dense layers with Dropout for regularization\n",
        "        self.fc1 = nn.Linear(64, 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input Check (NASA Standard)\n",
        "        if x.dim() != 4:\n",
        "            raise ValueError(f\"Expected 4D tensor (B, C, H, W), got {x.dim()}D\")\n",
        "\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErZ7P9Or3gHL"
      },
      "source": [
        "# Orquestador de Pruebas (Smoke Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "87b49459446b4ddab246a3e889a2f7c9",
            "17a5e51212414f0b9accf3f595096b22",
            "df9cc249ca314c859286a8e904e0e674",
            "eb1fa6edfa42475aa6bd5f9d8931ebaf",
            "7f31dcf41ae04e038acceb8da05d2330",
            "c2af7d8992b248988f524937d9de53a5",
            "ff5349906eed43d7aa1467499411ed74",
            "588c815d676a4b17b0bd7c10320956cb",
            "c8ddd4274bb246a7b4dbf569e5cb7f1e",
            "d98d839e6ef14f70ab61c7d1465119e3",
            "7e79666de8ea4bdfbc8f756770b27da8"
          ]
        },
        "id": "dCrvHJV_3grX",
        "outputId": "4bac52c4-d0ca-49f9-fa7c-5a53ef4f6641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Running on: cpu\n",
            "ðŸ› ï¸ Starting System Integrity Check...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/deepfake-audio-lab/src/deepfake_audio/application/trainer.py:19: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = GradScaler() # Optimization for Colab Pro GPUs\n",
            "/usr/local/lib/python3.12/dist-packages/torch/cuda/amp/grad_scaler.py:31: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  super().__init__(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87b49459446b4ddab246a3e889a2f7c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/deepfake-audio-lab/src/deepfake_audio/application/trainer.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.12/dist-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… System Integrity Verified. Loss: 0.7033, Accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import sys\n",
        "\n",
        "# Add the project's 'src' directory to the system path for module imports\n",
        "sys.path.insert(0, str(ROOT_DIR / 'src'))\n",
        "\n",
        "# Import the necessary classes\n",
        "from deepfake_audio.domain.models import SonicIdentityNet\n",
        "from deepfake_audio.application.trainer import ResearchTrainer\n",
        "\n",
        "# Environment diagnostic\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ðŸš€ Running on: {device}\")\n",
        "\n",
        "# Synthetic data for architectural validation\n",
        "# 100 samples, 1 channel, 64x64 spectrograms\n",
        "dummy_data = torch.randn(100, 1, 64, 64)\n",
        "dummy_labels = torch.randint(0, 2, (100,))\n",
        "dataset = TensorDataset(dummy_data, dummy_labels)\n",
        "loader = DataLoader(dataset, batch_size=16)\n",
        "\n",
        "# Initialize laboratory components\n",
        "model = SonicIdentityNet()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = ResearchTrainer(model, optimizer, criterion, device, config={})\n",
        "\n",
        "# Execute System Check\n",
        "print(\"ðŸ› ï¸ Starting System Integrity Check...\")\n",
        "try:\n",
        "    loss = trainer.train_epoch(loader)\n",
        "    acc = trainer.validate(loader)\n",
        "    print(f\"âœ… System Integrity Verified. Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ System Check Failed: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuovHjp-4pgh"
      },
      "source": [
        "# Unit Testing de Rigor MatemÃ¡tico (Standard: Max Planck)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsI-cQCt5Zfm",
        "outputId": "8572c4b7-4631-4483-e13f-69ac4b523c25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/deepfake-audio-lab/tests/test_mathematical_core.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {ROOT_DIR}/tests/test_mathematical_core.py\n",
        "\"\"\"\n",
        "Mathematical Rigor & Formula Validation.\n",
        "Ensures zero-invention of formulas and adherence to corpus documentation.\n",
        "\"\"\"\n",
        "import unittest\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- SYSTEM INTEGRITY PATCH ---\n",
        "# Automatically resolve project root relative to this file\n",
        "FILE_PATH = Path(__file__).resolve()\n",
        "PROJECT_ROOT = FILE_PATH.parent.parent  # Go up from tests/ -> deepfake-audio-lab/\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "# ------------------------------\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from src.deepfake_audio.infrastructure.numerics.stability import NumericalGuard\n",
        "from src.deepfake_audio.infrastructure.features.topological_engine import SonicSignature\n",
        "\n",
        "class TestThesisMathematics(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.guard = NumericalGuard()\n",
        "        # Initialize with standard thesis parameters (Delay=1, Dim=3)\n",
        "        self.tda_engine = SonicSignature(dimension=3, delay=1)\n",
        "\n",
        "    def test_epsilon_guard(self):\n",
        "        \"\"\"Validates that division by zero is handled style NASA/DARPA.\"\"\"\n",
        "        denominator = torch.tensor([0.0, 1e-12, -0.0])\n",
        "        numerator = torch.tensor([1.0, 1.0, 1.0])\n",
        "        result = self.guard.safe_divide(numerator, denominator)\n",
        "\n",
        "        # Must be finite and not crash\n",
        "        self.assertTrue(torch.isfinite(result).all(), \"Guard failed: Non-finite result detected.\")\n",
        "        # Check if padding worked (should not exceed 1/EPSILON approx)\n",
        "        self.assertTrue((result.abs() <= 1e11).all(), \"Guard failed: Value explosion detected.\")\n",
        "\n",
        "    def test_takens_embedding_invariance(self):\n",
        "        \"\"\"Validates the Takens Embedding Theorem implementation.\"\"\"\n",
        "        # Periodic signal (Sine wave) - Represents a stable attractor\n",
        "        t = np.linspace(0, 10, 100)\n",
        "        signal = np.sin(t)\n",
        "\n",
        "        # Generate topological fingerprint\n",
        "        fingerprint = self.tda_engine.generate_fingerprint(signal)\n",
        "\n",
        "        # Verification: H0 (Connected components) must exist\n",
        "        # Persistence diagrams shape: (n_samples, n_points, 3)\n",
        "        # We check if we have feature points extracted\n",
        "        self.assertGreater(fingerprint.shape[1], 0, \"Topological manifold failed to emerge.\")\n",
        "\n",
        "    def test_gradient_integrity(self):\n",
        "        \"\"\"Ensures gradients are finite, preventing 'System Locks'.\"\"\"\n",
        "        tensor = torch.tensor([1.0, np.nan, 2.0])\n",
        "        with self.assertRaises(ArithmeticError):\n",
        "            self.guard.validate_tensor(tensor, \"Integrity_Test\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=[''], exit=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDbd9EaX4tAQ"
      },
      "source": [
        "# EjecuciÃ³n de la AuditorÃ­a MatemÃ¡tica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoitxfsF5ivl",
        "outputId": "2ed7b35e-0058-4dc2-ff1b-0281707135b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ”§ Environment Path Configured: /content/deepfake-audio-lab\n",
            "Running Mathematical Rigor Tests...\n",
            "\n",
            ".ERROR:root:CRITICAL: Numerical instability in Integrity_Test\n",
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.005s\n",
            "\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# MATHEMATICAL AUDIT EXECUTION (CORRECTED)\n",
        "# Fixes ModuleNotFoundError by injecting Project Root into PYTHONPATH\n",
        "# ==============================================================================\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# We programmatically add the project root to sys.path to ensure\n",
        "# 'src' is always discoverable, regardless of where the test is run.\n",
        "project_root = \"/content/deepfake-audio-lab\"\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "\n",
        "print(f\"ðŸ”§ Environment Path Configured: {project_root}\")\n",
        "print(\"Running Mathematical Rigor Tests...\\n\")\n",
        "\n",
        "# Execute the test suite using the configured environment\n",
        "!PYTHONPATH=/content/deepfake-audio-lab python {ROOT_DIR}/tests/test_mathematical_core.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPgoB5s9Zku0XnN94vPD8sw",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
